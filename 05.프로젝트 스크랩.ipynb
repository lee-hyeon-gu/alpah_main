{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import sys\n",
    "if 'ipykernel' in sys.modules:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"--no-sandbox\")  # sandbox 주요 요소 처리불가-> nosandbox 처리 가능\n",
    "\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparQ Attention: Bandwidth-Efficient LLM Inference\n",
      "ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations\n",
      "DreaMoving: A Human Dance Video Generation Framework based on Diffusion Models\n",
      "PathFinder: Guided Search over Multi-Step Reasoning Paths\n",
      "Customizing Motion in Text-to-Video Diffusion Models\n",
      "Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models\n",
      "Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors\n",
      "EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism\n",
      "MVDD: Multi-View Depth Diffusion Models\n",
      "Localized Symbolic Knowledge Distillation for Visual Commonsense Models\n"
     ]
    }
   ],
   "source": [
    "url='https://huggingface.co/papers'\n",
    "driver.get(url)\n",
    "time.sleep(0.2)\n",
    "\n",
    "all_title=[]\n",
    "all_news=[]\n",
    "all_url=[]\n",
    "all_author=[] \n",
    "\n",
    "titles=driver.find_elements(By.TAG_NAME,'h3')\n",
    "\n",
    "for i in titles:\n",
    "    all_title.append(i.text)\n",
    "all_title=[i for i in all_title if i] \n",
    "\n",
    "\n",
    "for n in all_title:\n",
    "\n",
    "    print(n)\n",
    "    driver.find_element(By.PARTIAL_LINK_TEXT,n).click() #페이지 들어가기\n",
    "    time.sleep(1)\n",
    "    \n",
    "    nourl=driver.current_url#url 저장\n",
    "    all_url.append(nourl)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    news=driver.find_element(By.TAG_NAME,'p') # 뉴스 본문 저장\n",
    "    all_news.append(news.text)\n",
    "\n",
    "  \n",
    "    author=driver.find_element(By.CLASS_NAME,'whitespace-nowrap.underline') #저자 \n",
    "    all_author.append(author.text)\n",
    "        \n",
    "    \n",
    "    driver.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SparQ Attention: Bandwidth-Efficient LLM Infer...</td>\n",
       "      <td>Generative large language models (LLMs) have o...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04985</td>\n",
       "      <td>Luka Ribar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECLIPSE: A Resource-Efficient Text-to-Image Pr...</td>\n",
       "      <td>Text-to-image (T2I) diffusion models, notably ...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04655</td>\n",
       "      <td>Maitreya Patel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DreaMoving: A Human Dance Video Generation Fra...</td>\n",
       "      <td>In this paper, we present DreaMoving, a diffus...</td>\n",
       "      <td>https://huggingface.co/papers/2312.05107</td>\n",
       "      <td>Mengyang Feng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PathFinder: Guided Search over Multi-Step Reas...</td>\n",
       "      <td>With recent advancements in large language mod...</td>\n",
       "      <td>https://huggingface.co/papers/2312.05180</td>\n",
       "      <td>Olga Golovneva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customizing Motion in Text-to-Video Diffusion ...</td>\n",
       "      <td>We introduce an approach for augmenting text-t...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04966</td>\n",
       "      <td>Joanna Materzynska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Purple Llama CyberSecEval: A Secure Coding Ben...</td>\n",
       "      <td>This paper presents CyberSecEval, a comprehens...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04724</td>\n",
       "      <td>Manish Bhatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Text-to-3D Generation with Bidirectional Diffu...</td>\n",
       "      <td>Most 3D generation research focuses on up-proj...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04963</td>\n",
       "      <td>Lihe Ding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EE-LLM: Large-Scale Training and Inference of ...</td>\n",
       "      <td>We present EE-LLM, a framework for large-scale...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04916</td>\n",
       "      <td>Yanxi Chen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MVDD: Multi-View Depth Diffusion Models</td>\n",
       "      <td>Denoising diffusion models have demonstrated o...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04875</td>\n",
       "      <td>Zhen Wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Localized Symbolic Knowledge Distillation for ...</td>\n",
       "      <td>Instruction following vision-language (VL) mod...</td>\n",
       "      <td>https://huggingface.co/papers/2312.04837</td>\n",
       "      <td>Jae Sung Park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  SparQ Attention: Bandwidth-Efficient LLM Infer...   \n",
       "1  ECLIPSE: A Resource-Efficient Text-to-Image Pr...   \n",
       "2  DreaMoving: A Human Dance Video Generation Fra...   \n",
       "3  PathFinder: Guided Search over Multi-Step Reas...   \n",
       "4  Customizing Motion in Text-to-Video Diffusion ...   \n",
       "5  Purple Llama CyberSecEval: A Secure Coding Ben...   \n",
       "6  Text-to-3D Generation with Bidirectional Diffu...   \n",
       "7  EE-LLM: Large-Scale Training and Inference of ...   \n",
       "8            MVDD: Multi-View Depth Diffusion Models   \n",
       "9  Localized Symbolic Knowledge Distillation for ...   \n",
       "\n",
       "                                                news  \\\n",
       "0  Generative large language models (LLMs) have o...   \n",
       "1  Text-to-image (T2I) diffusion models, notably ...   \n",
       "2  In this paper, we present DreaMoving, a diffus...   \n",
       "3  With recent advancements in large language mod...   \n",
       "4  We introduce an approach for augmenting text-t...   \n",
       "5  This paper presents CyberSecEval, a comprehens...   \n",
       "6  Most 3D generation research focuses on up-proj...   \n",
       "7  We present EE-LLM, a framework for large-scale...   \n",
       "8  Denoising diffusion models have demonstrated o...   \n",
       "9  Instruction following vision-language (VL) mod...   \n",
       "\n",
       "                                        url              author  \n",
       "0  https://huggingface.co/papers/2312.04985          Luka Ribar  \n",
       "1  https://huggingface.co/papers/2312.04655      Maitreya Patel  \n",
       "2  https://huggingface.co/papers/2312.05107       Mengyang Feng  \n",
       "3  https://huggingface.co/papers/2312.05180      Olga Golovneva  \n",
       "4  https://huggingface.co/papers/2312.04966  Joanna Materzynska  \n",
       "5  https://huggingface.co/papers/2312.04724        Manish Bhatt  \n",
       "6  https://huggingface.co/papers/2312.04963           Lihe Ding  \n",
       "7  https://huggingface.co/papers/2312.04916          Yanxi Chen  \n",
       "8  https://huggingface.co/papers/2312.04875           Zhen Wang  \n",
       "9  https://huggingface.co/papers/2312.04837       Jae Sung Park  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumnews=[]\n",
    "for t,n,u,a in zip(all_title,all_news,all_url,all_author):\n",
    "    singles={'title':t,'news':n,'url':u,'author':a}\n",
    "    sumnews.append(singles)\n",
    "\n",
    "import pandas as pd\n",
    "news_df=pd.DataFrame(sumnews)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_excel('samtest.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
