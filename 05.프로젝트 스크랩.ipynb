{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import sys\n",
    "if 'ipykernel' in sys.modules:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument(\"--headless\")\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"--no-sandbox\")  # sandbox 주요 요소 처리불가-> nosandbox 처리 가능\n",
    "\n",
    "#headers={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'}\n",
    "#options.add_argument('headers')\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://cdn-uploads.huggingface.co/production/uploads/60f1abe7544c2adfd699860c/pPBftW9u_SvGH1HLzFDu-.mp4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url='https://huggingface.co/papers/2312.07409'\n",
    "driver.get(url)\n",
    "\n",
    "all_video=[]\n",
    "all_video_url=[]\n",
    "\n",
    "\n",
    "if driver.find_elements(By.TAG_NAME,'video'): # 동영상\n",
    "    all_video.append('yes')\n",
    "    image=driver.find_element(By.XPATH,'/html/body/div/main/div/section[1]/div/video')\n",
    "    img_srtc=image.get_attribute('src')\n",
    "    all_video_url.append(img_srtc)\n",
    "    print(all_video_url)\n",
    "else:\n",
    "    all_video.append('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEC\\n13']\n",
      "FreeInit: Bridging Initialization Gap in Video Diffusion Models\n",
      "FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition\n",
      "DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing\n",
      "VILA: On Pre-training for Visual Language Models\n",
      "Alignment for Honesty\n",
      "CCM: Adding Conditional Controls to Text-to-Image Consistency Models\n",
      "Steering Llama 2 via Contrastive Activation Addition\n",
      "Interfacing Foundation Models' Embeddings\n",
      "COLMAP-Free 3D Gaussian Splatting\n",
      "Rethinking Compression: Reduced Order Modelling of Latent Features in Large Language Models\n",
      "Honeybee: Locality-enhanced Projector for Multimodal LLM\n",
      "How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation\n",
      "Fast Training of Diffusion Transformer with Extreme Masking for 3D Point Clouds Generation\n",
      "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations\n",
      "PEEKABOO: Interactive Video Generation via Masked-Diffusion\n",
      "\"I Want It That Way\": Enabling Interactive Decision Support Using Large Language Models and Constraint Programming\n",
      "                                                title  \\\n",
      "0   FreeInit: Bridging Initialization Gap in Video...   \n",
      "1   FreeControl: Training-Free Spatial Control of ...   \n",
      "2   DiffMorpher: Unleashing the Capability of Diff...   \n",
      "3    VILA: On Pre-training for Visual Language Models   \n",
      "4                               Alignment for Honesty   \n",
      "5   CCM: Adding Conditional Controls to Text-to-Im...   \n",
      "6   Steering Llama 2 via Contrastive Activation Ad...   \n",
      "7           Interfacing Foundation Models' Embeddings   \n",
      "8                   COLMAP-Free 3D Gaussian Splatting   \n",
      "9   Rethinking Compression: Reduced Order Modellin...   \n",
      "10  Honeybee: Locality-enhanced Projector for Mult...   \n",
      "11  How Well Does GPT-4V(ision) Adapt to Distribut...   \n",
      "12  Fast Training of Diffusion Transformer with Ex...   \n",
      "13  Llama Guard: LLM-based Input-Output Safeguard ...   \n",
      "14  PEEKABOO: Interactive Video Generation via Mas...   \n",
      "15  \"I Want It That Way\": Enabling Interactive Dec...   \n",
      "\n",
      "                                                 news  \\\n",
      "0   Though diffusion-based video generation has wi...   \n",
      "1   Recent approaches such as ControlNet offer use...   \n",
      "2   Diffusion models have achieved remarkable imag...   \n",
      "3   Visual language models (VLMs) rapidly progress...   \n",
      "4   Recent research has made significant strides i...   \n",
      "5   Consistency Models (CMs) have showed a promise...   \n",
      "6   We introduce Contrastive Activation Addition (...   \n",
      "7   We present FIND, a generalized interface for a...   \n",
      "8   While neural rendering has led to impressive a...   \n",
      "9   Due to the substantial scale of Large Language...   \n",
      "10  In Multimodal Large Language Models (MLLMs), a...   \n",
      "11  In machine learning, generalization against di...   \n",
      "12  Diffusion Transformers have recently shown rem...   \n",
      "13  We introduce Llama Guard, an LLM-based input-o...   \n",
      "14  Recently there has been a lot of progress in t...   \n",
      "15  A critical factor in the success of decision s...   \n",
      "\n",
      "                                         url          author like    day  \\\n",
      "0   https://huggingface.co/papers/2312.07537     Tianxing Wu   21  DEC13   \n",
      "1   https://huggingface.co/papers/2312.07536      Sicheng Mo   12  DEC13   \n",
      "2   https://huggingface.co/papers/2312.07409    Kaiwen Zhang   11  DEC13   \n",
      "3   https://huggingface.co/papers/2312.07533          Ji Lin   11  DEC13   \n",
      "4   https://huggingface.co/papers/2312.07000     Yuqing Yang    9  DEC13   \n",
      "5   https://huggingface.co/papers/2312.06971        Jie Xiao    8  DEC13   \n",
      "6   https://huggingface.co/papers/2312.06681     Nina Rimsky    7  DEC13   \n",
      "7   https://huggingface.co/papers/2312.07532      Xueyan Zou    6  DEC13   \n",
      "8   https://huggingface.co/papers/2312.07504         Yang Fu    6  DEC13   \n",
      "9   https://huggingface.co/papers/2312.07046    Arnav Chavan    6  DEC13   \n",
      "10  https://huggingface.co/papers/2312.06742      Junbum Cha    6  DEC13   \n",
      "11  https://huggingface.co/papers/2312.07424     Zhongyi Han    5  DEC13   \n",
      "12  https://huggingface.co/papers/2312.07231     Shentong Mo    4  DEC13   \n",
      "13  https://huggingface.co/papers/2312.06674      Hakan Inan    4  DEC13   \n",
      "14  https://huggingface.co/papers/2312.07509       Yash Jain    3  DEC13   \n",
      "15  https://huggingface.co/papers/2312.06908  Connor Lawless    2  DEC13   \n",
      "\n",
      "   video                                          video_url  \n",
      "0     no                                                  -  \n",
      "1     no                                                  -  \n",
      "2    yes  https://cdn-uploads.huggingface.co/production/...  \n",
      "3     no                                                  -  \n",
      "4     no                                                  -  \n",
      "5     no                                                  -  \n",
      "6     no                                                  -  \n",
      "7     no                                                  -  \n",
      "8     no                                                  -  \n",
      "9     no                                                  -  \n",
      "10    no                                                  -  \n",
      "11    no                                                  -  \n",
      "12    no                                                  -  \n",
      "13    no                                                  -  \n",
      "14   yes  https://cdn-uploads.huggingface.co/production/...  \n",
      "15    no                                                  -  \n"
     ]
    }
   ],
   "source": [
    "url='https://huggingface.co/papers?date=2023-12-13'\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# 전 날 페이지로 넘기기\n",
    "# for d in range(2):\n",
    "\n",
    "all_title=[]\n",
    "all_news=[]\n",
    "all_url=[]\n",
    "all_author=[] \n",
    "all_stars=[]\n",
    "all_days=[]\n",
    "word=[]\n",
    "all_images=[]\n",
    "all_images_url=[]\n",
    "all_video=[]\n",
    "all_video_url=[]\n",
    "\n",
    "titles=driver.find_elements(By.TAG_NAME,'h3')# 제목\n",
    "stars=driver.find_elements(By.TAG_NAME,'a>div>div') # 좋아요\n",
    "day=driver.find_elements(By.TAG_NAME,'time')\n",
    "\n",
    "for i in titles:\n",
    "    all_title.append(i.text)\n",
    "all_title=[i for i in all_title if i]  # 빈칸제거\n",
    "\n",
    "for i in stars:\n",
    "    all_stars.append(i.text)\n",
    "\n",
    "for i in day:\n",
    "    all_days.append(i.text)\n",
    "\n",
    "print(all_days)\n",
    "    \n",
    "word=all_days[0]\n",
    "word=word.replace('\\n','')\n",
    "all_days2=[]\n",
    "all_days2.append(word)\n",
    "\n",
    "\n",
    "for n in all_title:\n",
    "\n",
    "    print(n)\n",
    "    driver.find_element(By.PARTIAL_LINK_TEXT,n).click() #페이지 들어가기\n",
    "    time.sleep(1)\n",
    "    \n",
    "    nourl=driver.current_url#url 저장\n",
    "    all_url.append(nourl)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    news=driver.find_element(By.TAG_NAME,'p') # 뉴스 본문 저장\n",
    "    all_news.append(news.text)\n",
    "\n",
    "\n",
    "    author=driver.find_element(By.CLASS_NAME,'whitespace-nowrap.underline') #저자 \n",
    "    all_author.append(author.text)\n",
    "\n",
    "\n",
    "    # if driver.find_elements(By.TAG_NAME,'img'): #이미지 paper 에는 이미지 없음\n",
    "    #     all_images.append('yes')\n",
    "    #     image=driver.find_element(By.XPATH,'/html/body/div/main/div[2]/section[1]/div[3]/div[2]/p[4]/a/img')\n",
    "    #     img_srtc=image.get_attribute('src')\n",
    "    #     all_images_url.append(img_srtc)\n",
    "    # else:\n",
    "    #     all_images.append('yes')\n",
    "        \n",
    "\n",
    "    if driver.find_elements(By.TAG_NAME,'video'): # 동영상\n",
    "        all_video.append('yes')\n",
    "        image=driver.find_element(By.XPATH,'/html/body/div/main/div/section[1]/div/video')\n",
    "        img_srtc=image.get_attribute('src')\n",
    "        all_video_url.append(img_srtc)\n",
    "    else:\n",
    "        all_video.append('no')\n",
    "        all_video_url.append('-')\n",
    "\n",
    "    driver.back()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # # 잠깐 쉬고 전 페이지 가기\n",
    "    # time.sleep(3)\n",
    "    # driver.find_element(By.CLASS_NAME,'btn.gap-2').click() # 사이트 전 날\n",
    "\n",
    "all_days2=all_days2*len(all_title) # 날짜 개수 제목개수만큼 늘리기\n",
    "\n",
    "\n",
    "sumnews=[]\n",
    "for t,n,u,a,s,d,v,vr in zip(all_title,all_news,all_url,all_author,all_stars,all_days2,all_video,all_video_url):\n",
    "    singles={'title':t,'news':n,'url':u,'author':a,'like':s,'day':d,'video':v,'video_url':vr}\n",
    "    sumnews.append(singles)\n",
    "\n",
    "import pandas as pd\n",
    "news_df=pd.DataFrame(sumnews)\n",
    "print(news_df)\n",
    "\n",
    "import os\n",
    "if not os.path.exists('output.csv'):\n",
    "    news_df.to_csv('output.csv', index=False, mode='w', encoding='utf-8-sig')\n",
    "else:\n",
    "    news_df.to_csv('output.csv', index=False, mode='a', encoding='utf-8-sig', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>like</th>\n",
       "      <th>day</th>\n",
       "      <th>video</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FreeInit: Bridging Initialization Gap in Video...</td>\n",
       "      <td>Though diffusion-based video generation has wi...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07537</td>\n",
       "      <td>Tianxing Wu</td>\n",
       "      <td>21</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FreeControl: Training-Free Spatial Control of ...</td>\n",
       "      <td>Recent approaches such as ControlNet offer use...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07536</td>\n",
       "      <td>Sicheng Mo</td>\n",
       "      <td>12</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiffMorpher: Unleashing the Capability of Diff...</td>\n",
       "      <td>Diffusion models have achieved remarkable imag...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07409</td>\n",
       "      <td>Kaiwen Zhang</td>\n",
       "      <td>11</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>yes</td>\n",
       "      <td>https://cdn-uploads.huggingface.co/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VILA: On Pre-training for Visual Language Models</td>\n",
       "      <td>Visual language models (VLMs) rapidly progress...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07533</td>\n",
       "      <td>Ji Lin</td>\n",
       "      <td>11</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alignment for Honesty</td>\n",
       "      <td>Recent research has made significant strides i...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07000</td>\n",
       "      <td>Yuqing Yang</td>\n",
       "      <td>9</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCM: Adding Conditional Controls to Text-to-Im...</td>\n",
       "      <td>Consistency Models (CMs) have showed a promise...</td>\n",
       "      <td>https://huggingface.co/papers/2312.06971</td>\n",
       "      <td>Jie Xiao</td>\n",
       "      <td>8</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steering Llama 2 via Contrastive Activation Ad...</td>\n",
       "      <td>We introduce Contrastive Activation Addition (...</td>\n",
       "      <td>https://huggingface.co/papers/2312.06681</td>\n",
       "      <td>Nina Rimsky</td>\n",
       "      <td>7</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Interfacing Foundation Models' Embeddings</td>\n",
       "      <td>We present FIND, a generalized interface for a...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07532</td>\n",
       "      <td>Xueyan Zou</td>\n",
       "      <td>6</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COLMAP-Free 3D Gaussian Splatting</td>\n",
       "      <td>While neural rendering has led to impressive a...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07504</td>\n",
       "      <td>Yang Fu</td>\n",
       "      <td>6</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rethinking Compression: Reduced Order Modellin...</td>\n",
       "      <td>Due to the substantial scale of Large Language...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07046</td>\n",
       "      <td>Arnav Chavan</td>\n",
       "      <td>6</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Honeybee: Locality-enhanced Projector for Mult...</td>\n",
       "      <td>In Multimodal Large Language Models (MLLMs), a...</td>\n",
       "      <td>https://huggingface.co/papers/2312.06742</td>\n",
       "      <td>Junbum Cha</td>\n",
       "      <td>6</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How Well Does GPT-4V(ision) Adapt to Distribut...</td>\n",
       "      <td>In machine learning, generalization against di...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07424</td>\n",
       "      <td>Zhongyi Han</td>\n",
       "      <td>5</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fast Training of Diffusion Transformer with Ex...</td>\n",
       "      <td>Diffusion Transformers have recently shown rem...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07231</td>\n",
       "      <td>Shentong Mo</td>\n",
       "      <td>4</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Llama Guard: LLM-based Input-Output Safeguard ...</td>\n",
       "      <td>We introduce Llama Guard, an LLM-based input-o...</td>\n",
       "      <td>https://huggingface.co/papers/2312.06674</td>\n",
       "      <td>Hakan Inan</td>\n",
       "      <td>4</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PEEKABOO: Interactive Video Generation via Mas...</td>\n",
       "      <td>Recently there has been a lot of progress in t...</td>\n",
       "      <td>https://huggingface.co/papers/2312.07509</td>\n",
       "      <td>Yash Jain</td>\n",
       "      <td>3</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>yes</td>\n",
       "      <td>https://cdn-uploads.huggingface.co/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"I Want It That Way\": Enabling Interactive Dec...</td>\n",
       "      <td>A critical factor in the success of decision s...</td>\n",
       "      <td>https://huggingface.co/papers/2312.06908</td>\n",
       "      <td>Connor Lawless</td>\n",
       "      <td>2</td>\n",
       "      <td>DEC13</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   FreeInit: Bridging Initialization Gap in Video...   \n",
       "1   FreeControl: Training-Free Spatial Control of ...   \n",
       "2   DiffMorpher: Unleashing the Capability of Diff...   \n",
       "3    VILA: On Pre-training for Visual Language Models   \n",
       "4                               Alignment for Honesty   \n",
       "5   CCM: Adding Conditional Controls to Text-to-Im...   \n",
       "6   Steering Llama 2 via Contrastive Activation Ad...   \n",
       "7           Interfacing Foundation Models' Embeddings   \n",
       "8                   COLMAP-Free 3D Gaussian Splatting   \n",
       "9   Rethinking Compression: Reduced Order Modellin...   \n",
       "10  Honeybee: Locality-enhanced Projector for Mult...   \n",
       "11  How Well Does GPT-4V(ision) Adapt to Distribut...   \n",
       "12  Fast Training of Diffusion Transformer with Ex...   \n",
       "13  Llama Guard: LLM-based Input-Output Safeguard ...   \n",
       "14  PEEKABOO: Interactive Video Generation via Mas...   \n",
       "15  \"I Want It That Way\": Enabling Interactive Dec...   \n",
       "\n",
       "                                                 news  \\\n",
       "0   Though diffusion-based video generation has wi...   \n",
       "1   Recent approaches such as ControlNet offer use...   \n",
       "2   Diffusion models have achieved remarkable imag...   \n",
       "3   Visual language models (VLMs) rapidly progress...   \n",
       "4   Recent research has made significant strides i...   \n",
       "5   Consistency Models (CMs) have showed a promise...   \n",
       "6   We introduce Contrastive Activation Addition (...   \n",
       "7   We present FIND, a generalized interface for a...   \n",
       "8   While neural rendering has led to impressive a...   \n",
       "9   Due to the substantial scale of Large Language...   \n",
       "10  In Multimodal Large Language Models (MLLMs), a...   \n",
       "11  In machine learning, generalization against di...   \n",
       "12  Diffusion Transformers have recently shown rem...   \n",
       "13  We introduce Llama Guard, an LLM-based input-o...   \n",
       "14  Recently there has been a lot of progress in t...   \n",
       "15  A critical factor in the success of decision s...   \n",
       "\n",
       "                                         url          author like    day  \\\n",
       "0   https://huggingface.co/papers/2312.07537     Tianxing Wu   21  DEC13   \n",
       "1   https://huggingface.co/papers/2312.07536      Sicheng Mo   12  DEC13   \n",
       "2   https://huggingface.co/papers/2312.07409    Kaiwen Zhang   11  DEC13   \n",
       "3   https://huggingface.co/papers/2312.07533          Ji Lin   11  DEC13   \n",
       "4   https://huggingface.co/papers/2312.07000     Yuqing Yang    9  DEC13   \n",
       "5   https://huggingface.co/papers/2312.06971        Jie Xiao    8  DEC13   \n",
       "6   https://huggingface.co/papers/2312.06681     Nina Rimsky    7  DEC13   \n",
       "7   https://huggingface.co/papers/2312.07532      Xueyan Zou    6  DEC13   \n",
       "8   https://huggingface.co/papers/2312.07504         Yang Fu    6  DEC13   \n",
       "9   https://huggingface.co/papers/2312.07046    Arnav Chavan    6  DEC13   \n",
       "10  https://huggingface.co/papers/2312.06742      Junbum Cha    6  DEC13   \n",
       "11  https://huggingface.co/papers/2312.07424     Zhongyi Han    5  DEC13   \n",
       "12  https://huggingface.co/papers/2312.07231     Shentong Mo    4  DEC13   \n",
       "13  https://huggingface.co/papers/2312.06674      Hakan Inan    4  DEC13   \n",
       "14  https://huggingface.co/papers/2312.07509       Yash Jain    3  DEC13   \n",
       "15  https://huggingface.co/papers/2312.06908  Connor Lawless    2  DEC13   \n",
       "\n",
       "   video                                          video_url  \n",
       "0     no                                                  -  \n",
       "1     no                                                  -  \n",
       "2    yes  https://cdn-uploads.huggingface.co/production/...  \n",
       "3     no                                                  -  \n",
       "4     no                                                  -  \n",
       "5     no                                                  -  \n",
       "6     no                                                  -  \n",
       "7     no                                                  -  \n",
       "8     no                                                  -  \n",
       "9     no                                                  -  \n",
       "10    no                                                  -  \n",
       "11    no                                                  -  \n",
       "12    no                                                  -  \n",
       "13    no                                                  -  \n",
       "14   yes  https://cdn-uploads.huggingface.co/production/...  \n",
       "15    no                                                  -  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago', '6 days ago']\n",
      "['yes']\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"e85c160ef56cfb2453095867ed93d43d\", element=\"48F15FD037DD7B17FC92181CE2F0D398_element_344\")>]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url='https://huggingface.co/papers/2312.03461'\n",
    "driver.get(url)\n",
    "all_days=[]\n",
    "# day=driver.find_elements(By.CLASS_NAME,'relative.flex.flex-col.items-stretch')\n",
    "day=driver.find_elements(By.TAG_NAME,'time')\n",
    "\n",
    "for i in day:\n",
    "    all_days.append(i.text)\n",
    "\n",
    "word=all_days[0]\n",
    "word=word.replace('\\n','')\n",
    "all_days=[]\n",
    "all_days.append(word)\n",
    "\n",
    "all_days=all_days*len(all_title)\n",
    "print(all_days)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_video=[]\n",
    "all_video_url=[]\n",
    "if driver.find_elements(By.TAG_NAME,'video'):\n",
    "    all_video.append('yes')\n",
    "    print(all_video)\n",
    "    videourl=driver.find_elements(By.XPATH,'/html/body/div/main/div/section[1]/div/video')\n",
    "    print(videourl)\n",
    "\n",
    "    for i in videourl:\n",
    "        asd=i.get_attribute('video')\n",
    "        print(asd)\n",
    "\n",
    "else:\n",
    "    all_video.append('no')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
